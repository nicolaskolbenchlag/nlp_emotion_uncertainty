MuSe-LSTM-Attention-baseline-model/extract_features/emotion_recognition/main.py --feature_set bert-4 --emo_dim_set valence --epochs 100 --refresh --n_seeds 1 --seed 314 --predict --attn --rnn_bi --loss cwCCC --uncertainty_approach cw_ccc
Constructing dataset and data loader ...
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -1.0, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.9549, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.98725, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.9706, max 0.9218999999999999).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.8137000000000001, max 1.0).
Constructing data from scratch ...
Samples in partitions: (3122, 62, 64)
Input feature dim: 768.
==================================================
Training model... [seed 314]
