/nas/student/NicolasKolbenschlag/emotion_uncertainty/MuSe-LSTM-Attention-baseline-model/extract_features/emotion_recognition/main.py --feature_set bert-4 --emo_dim_set valence --epochs 100 --refresh --n_seeds 1 --seed 314 --attn --rnn_bi --loss ccc --rnn_dr .3 --attn_dr .3 --out_dr .3 --uncertainty_approach monte_carlo_dropout --predict
Constructing dataset and data loader ...
Constructing data from scratch ...
Samples in partitions: (3122, 62, 64)
Input feature dim: 768.
==================================================
Training model... [seed 314]
/nas/student/NicolasKolbenschlag/emotion_uncertainty/venv/lib/python3.7/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
Note: target can not be optimized for 15 consecutive epochs, early stop the training process!
Seed 314 | Best [Val CCC]: 0.3996 [' 0.3996']| Loss: 0.6169 | PCC: 0.4008 ['0.4008'] | RMSE: 0.4552 ['0.4552']
On Test: CCC  0.5685 | PCC  0.5702 | RMSE  0.3969
==================================================
On ground-truth labels:	Best	[Val CCC] for seed "314":	 0.3996
On ground-truth labels:		[Test CCC] for seed "314":	 0.5685
----------------------------------------------------------------------------------------------------
Predict val & test videos...
...done.
Delete model "MuSe-LSTM-Attention-baseline-model/output/model/2021-01-30-13-50_[bert-4]_[valence]_[NOSEG]_[lstm_64_1_True]_[True_1_4]_[0.005_1024_0.3_0.3_0.3]_None_[1_314_None_None].pth".
slurmstepd: Exceeded step memory limit at some point.
